{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782ee0f9",
   "metadata": {},
   "source": [
    "#### 1. Hello,Data!\n",
    "* Read the csv file into records.\n",
    "* Prnt the first 3 rows from the csv file.\n",
    "* .shape is used to verify dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a13dca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row*Column: (1000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>Order Priority</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Total Cost</th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Libya</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>Offline</td>\n",
       "      <td>M</td>\n",
       "      <td>10/18/2014</td>\n",
       "      <td>686800706</td>\n",
       "      <td>10/31/2014</td>\n",
       "      <td>8446</td>\n",
       "      <td>437.20</td>\n",
       "      <td>263.33</td>\n",
       "      <td>3692591.20</td>\n",
       "      <td>2224085.18</td>\n",
       "      <td>1468506.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>Online</td>\n",
       "      <td>M</td>\n",
       "      <td>11/7/2011</td>\n",
       "      <td>185941302</td>\n",
       "      <td>12/8/2011</td>\n",
       "      <td>3018</td>\n",
       "      <td>154.06</td>\n",
       "      <td>90.93</td>\n",
       "      <td>464953.08</td>\n",
       "      <td>274426.74</td>\n",
       "      <td>190526.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Libya</td>\n",
       "      <td>Baby Food</td>\n",
       "      <td>Offline</td>\n",
       "      <td>C</td>\n",
       "      <td>10/31/2016</td>\n",
       "      <td>246222341</td>\n",
       "      <td>12/9/2016</td>\n",
       "      <td>1517</td>\n",
       "      <td>255.28</td>\n",
       "      <td>159.42</td>\n",
       "      <td>387259.76</td>\n",
       "      <td>241840.14</td>\n",
       "      <td>145419.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Region Country   Item Type Sales Channel  \\\n",
       "0  Middle East and North Africa   Libya   Cosmetics       Offline   \n",
       "1                 North America  Canada  Vegetables        Online   \n",
       "2  Middle East and North Africa   Libya   Baby Food       Offline   \n",
       "\n",
       "  Order Priority  Order Date   Order ID   Ship Date  Units Sold  Unit Price  \\\n",
       "0              M  10/18/2014  686800706  10/31/2014        8446      437.20   \n",
       "1              M   11/7/2011  185941302   12/8/2011        3018      154.06   \n",
       "2              C  10/31/2016  246222341   12/9/2016        1517      255.28   \n",
       "\n",
       "   Unit Cost  Total Revenue  Total Cost  Total Profit  \n",
       "0     263.33     3692591.20  2224085.18    1468506.02  \n",
       "1      90.93      464953.08   274426.74     190526.34  \n",
       "2     159.42      387259.76   241840.14     145419.62  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets with explicit file paths\n",
    "records = pd.read_csv(\"../data/1000 Sales Records.csv\")\n",
    "\n",
    "# Quick sanity check: print dataset shapes (rows, columns)\n",
    "print(\"Row*Column:\",records.shape)\n",
    "\n",
    "# View to first 3 rows\n",
    "records.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "971a4f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row*Column: (500, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lab suggest to have >=500 rows, restricts for 500 rows\n",
    "records =  pd.read_csv(\"../data/1000 Sales Records.csv\", nrows=500)\n",
    "\n",
    "# Quick sanity check: print dataset shapes (rows, columns)\n",
    "print(\"Row*Column:\",records.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9eb6c9",
   "metadata": {},
   "source": [
    "* The lab requires a dataset with at least **500 rows**, so used `nrows=500`.  \n",
    "\n",
    "We also print the shape of the DataFrame `(rows, columns)` to confirm we are on track."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa5427",
   "metadata": {},
   "source": [
    "#### 2. Pick the Right Container and Justify dict vs namedtuple vs sets(1–2 sentences)\n",
    "\n",
    "I feel the best pick for the container would be a **list of dictionaries**  as it can hold many flexible key-value pairs and also in the assignment it is mentioned to save cleaned data to JSON.\n",
    "Why its best because 'namedtuple' which is constant once defined and 'set' only sotres unique values and cannot ontain all the records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d623d",
   "metadata": {},
   "source": [
    "#### 3. Implement Functions and  Data structure\n",
    "* Lets convert the dataframe into a *list of dictionaries*.\n",
    "* Each row is converted into Python dictionary; key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cb762f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 500\n",
      "First record: {'Region': 'Middle East and North Africa', 'Country': 'Libya', 'Item Type': 'Cosmetics', 'Sales Channel': 'Offline', 'Order Priority': 'M', 'Order Date': '10/18/2014', 'Order ID': 686800706, 'Ship Date': '10/31/2014', 'Units Sold': 8446, 'Unit Price': 437.2, 'Unit Cost': 263.33, 'Total Revenue': 3692591.2, 'Total Cost': 2224085.18, 'Total Profit': 1468506.02}\n"
     ]
    }
   ],
   "source": [
    "def populate_data_structure(data: pd.DataFrame) -> list[dict]:\n",
    "       return data.to_dict(orient=\"records\")\n",
    "\n",
    "# Use the function on df_raw (first 500 rows loaded earlier)\n",
    "records_list = populate_data_structure(records)\n",
    "\n",
    "print(f\"Number of records: {len(records_list)}\")\n",
    "print(\"First record:\", records_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab4f8ec",
   "metadata": {},
   "source": [
    "#### 4. Bulk Loaded\n",
    "* Dataset is bulk loaded to our container (**List of Dictionary**) from DataFrame.\n",
    "* Entired dataset is stored in our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7bd246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records loaded: 500\n",
      "{'Region': 'Middle East and North Africa', 'Country': 'Libya', 'Item Type': 'Cosmetics', 'Sales Channel': 'Offline', 'Order Priority': 'M', 'Order Date': '10/18/2014', 'Order ID': 686800706, 'Ship Date': '10/31/2014', 'Units Sold': 8446, 'Unit Price': 437.2, 'Unit Cost': 263.33, 'Total Revenue': 3692591.2, 'Total Cost': 2224085.18, 'Total Profit': 1468506.02}\n",
      "{'Region': 'North America', 'Country': 'Canada', 'Item Type': 'Vegetables', 'Sales Channel': 'Online', 'Order Priority': 'M', 'Order Date': '11/7/2011', 'Order ID': 185941302, 'Ship Date': '12/8/2011', 'Units Sold': 3018, 'Unit Price': 154.06, 'Unit Cost': 90.93, 'Total Revenue': 464953.08, 'Total Cost': 274426.74, 'Total Profit': 190526.34}\n",
      "{'Region': 'Middle East and North Africa', 'Country': 'Libya', 'Item Type': 'Baby Food', 'Sales Channel': 'Offline', 'Order Priority': 'C', 'Order Date': '10/31/2016', 'Order ID': 246222341, 'Ship Date': '12/9/2016', 'Units Sold': 1517, 'Unit Price': 255.28, 'Unit Cost': 159.42, 'Total Revenue': 387259.76, 'Total Cost': 241840.14, 'Total Profit': 145419.62}\n"
     ]
    }
   ],
   "source": [
    "# Bulk load the DataFrame into a list of dictionaries\n",
    "records_list = populate_data_structure(records)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Number of records loaded: {len(records_list)}\")\n",
    "\n",
    "# Show the first 3 records as mentioned in the lab\n",
    "for rec in records_list[:3]:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd88d0",
   "metadata": {},
   "source": [
    "#### 5. Quick Profiling\tMin/mean/max price, unique city count (set)\n",
    "* Step1 : Since we dont have a city column in the csv, lets try to generate it. \n",
    "* Step2 : Post generating the column then start the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bbb1b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique countries: 171\n",
      "['Libya' 'Canada' 'Japan' 'Chad' 'Armenia' 'Eritrea' 'Montenegro'\n",
      " 'Jamaica' 'Fiji' 'Togo' 'Greece' 'Sudan' 'Maldives' 'Estonia' 'Greenland'\n",
      " 'Cape Verde' 'Senegal' 'Federated States of Micronesia' 'Bulgaria'\n",
      " 'Algeria' 'Mongolia' 'Grenada' 'Mauritius ' 'Morocco' 'Honduras' 'Benin'\n",
      " 'Equatorial Guinea' 'Swaziland' 'Trinidad and Tobago' 'Sweden' 'Belarus'\n",
      " 'Guinea-Bissau' 'Turkey' 'Central African Republic' 'Laos' 'Israel'\n",
      " 'Bhutan' 'Vanuatu' 'Burundi' 'Ukraine' 'Croatia' 'Madagascar' 'Malaysia'\n",
      " 'Uzbekistan' 'Italy' 'Nepal' 'Portugal' 'Panama' 'Botswana' 'Tanzania'\n",
      " 'Romania' 'Mali' 'Niger' 'Austria' 'India' 'Luxembourg' 'Iceland' 'Qatar'\n",
      " 'South Sudan' 'United Kingdom' 'Tunisia ' 'United States of America'\n",
      " 'Liberia' 'South Korea' 'Kenya' 'Rwanda' 'Cuba' 'Czech Republic'\n",
      " 'Philippines' 'El Salvador' 'Tonga' 'Democratic Republic of the Congo'\n",
      " 'Afghanistan' 'Tuvalu' 'Gabon' 'East Timor' 'Jordan' 'Cyprus' 'Malawi'\n",
      " 'United Arab Emirates' 'China' 'Somalia' 'Bangladesh' 'Egypt' 'Vietnam'\n",
      " 'Marshall Islands' 'Taiwan' 'Ireland' 'South Africa' 'Albania' 'Ghana'\n",
      " 'Saint Lucia' 'Macedonia' 'Germany' 'Poland' 'Namibia' 'Zimbabwe'\n",
      " 'Norway' 'Oman' 'Serbia' 'Brunei' 'Nicaragua' 'Lithuania'\n",
      " 'Republic of the Congo' 'Cameroon' 'Moldova ' 'Bahrain' 'Hungary' 'Iraq'\n",
      " 'Lesotho' 'Lebanon' 'Georgia' 'Ethiopia' 'Mexico' 'Nigeria'\n",
      " 'Solomon Islands' 'Burkina Faso' 'Kiribati' 'Comoros' 'Iran' 'Belize'\n",
      " 'Andorra' 'Slovakia' 'Antigua and Barbuda ' 'Myanmar' 'Nauru' 'Finland'\n",
      " 'Papua New Guinea' 'Mozambique' 'Spain' 'Belgium' \"Cote d'Ivoire\"\n",
      " 'Switzerland' 'Palau' 'Slovenia' 'Guinea' 'Russia' 'Seychelles '\n",
      " 'Costa Rica' 'Liechtenstein' 'Uganda' 'Guatemala' 'Thailand' 'Denmark'\n",
      " 'Angola' 'North Korea' 'Yemen' 'Dominican Republic' 'Vatican City'\n",
      " 'Djibouti' 'Malta' 'The Bahamas' 'Tajikistan' 'Saudi Arabia' 'Mauritania'\n",
      " 'New Zealand' 'Samoa ' 'Singapore' 'Pakistan' 'Sao Tome and Principe'\n",
      " 'Turkmenistan' 'Monaco' 'Saint Kitts and Nevis ' 'Cambodia' 'Kyrgyzstan'\n",
      " 'Indonesia' 'Kazakhstan' 'Australia' 'Syria' 'Azerbaijan' 'Barbados']\n"
     ]
    }
   ],
   "source": [
    "# Count unique countries\n",
    "unique_country_count = records[\"Country\"].nunique()\n",
    "print(f\"Number of unique countries: {unique_country_count}\")\n",
    "\n",
    "# List the unique countries\n",
    "unique_countries = records[\"Country\"].unique()\n",
    "print(unique_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09def17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with valid city: 462\n",
      "Rows with 'Unknown City': 38\n"
     ]
    }
   ],
   "source": [
    "from countryinfo import CountryInfo\n",
    "\n",
    "def get_city(country):\n",
    "    try:\n",
    "        return CountryInfo(country).capital()\n",
    "    except:\n",
    "        return \"Unknown City\"\n",
    "# Create shipping_city column\n",
    "records[\"shipping_city\"] = records[\"Country\"].apply(get_city)\n",
    "\n",
    "# Define the count of Unknown City\n",
    "unknown_count = (records[\"shipping_city\"] == \"Unknown City\").sum()\n",
    "\n",
    "# Lets have the count of rows with cities and Unknown\n",
    "print(f\"Rows with valid city: {len(records) - unknown_count}\")\n",
    "print(f\"Rows with 'Unknown City': {unknown_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "582f1452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min price: 9.33\n",
      "Mean price: 274.30\n",
      "Max price: 668.27\n",
      "Unique city count: 158\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Min, mean, max of Unit Price\n",
    "min_price = records[\"Unit Price\"].min()\n",
    "mean_price = records[\"Unit Price\"].mean()\n",
    "max_price = records[\"Unit Price\"].max()\n",
    "\n",
    "# Unique cities (using set)\n",
    "unique_cities = set(records[\"shipping_city\"])  \n",
    "unique_city_count = len(unique_cities)\n",
    "\n",
    "print(f\"Min price: {min_price:.2f}\")\n",
    "print(f\"Mean price: {mean_price:.2f}\")\n",
    "print(f\"Max price: {max_price:.2f}\")\n",
    "print(f\"Unique city count: {unique_city_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf07a9",
   "metadata": {},
   "source": [
    "#### 6. Identify at least three dirty data cases\n",
    "\n",
    "Checking for issues in:\n",
    "* Check date columns are stored as object.\n",
    "* Check for white space.\n",
    "* Check for how many city are no available.\n",
    "* Check logic between Ship date and Order Date.\n",
    "* Check for duplicates.\n",
    "* Check inconsistency in formating.\n",
    "* Check for outliners in price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1903dfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Date dtype: object\n",
      "Ship Date dtype: object\n",
      "Rows with trailing/leading spaces in Country: 22\n",
      "Rows with 'Unknown City': 38\n",
      "Rows where Ship Date < Order Date: 108\n",
      "Duplicate rows: 0\n",
      "Unique Item Types: ['Cosmetics' 'Vegetables' 'Baby Food' 'Cereal' 'Fruits' 'Clothes' 'Snacks'\n",
      " 'Household' 'Office Supplies' 'Beverages' 'Personal Care' 'Meat']\n",
      "Unique Item Types (lowercased): ['cosmetics' 'vegetables' 'baby food' 'cereal' 'fruits' 'clothes' 'snacks'\n",
      " 'household' 'office supplies' 'beverages' 'personal care' 'meat']\n",
      "Unique Countries (sample 20): ['Libya' 'Canada' 'Japan' 'Chad' 'Armenia' 'Eritrea' 'Montenegro'\n",
      " 'Jamaica' 'Fiji' 'Togo' 'Greece' 'Sudan' 'Maldives' 'Estonia' 'Greenland'\n",
      " 'Cape Verde' 'Senegal' 'Federated States of Micronesia' 'Bulgaria'\n",
      " 'Algeria']\n",
      "Invalid Units Sold count: 0\n",
      "Outlier Units Sold count: 0\n",
      "Invalid Revenue rows: 0\n",
      "Invalid Cost rows: 0\n",
      "Invalid Profit rows: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Check if date columns are stored as object\n",
    "print(\"Order Date dtype:\", records[\"Order Date\"].dtype)\n",
    "print(\"Ship Date dtype:\", records[\"Ship Date\"].dtype)\n",
    "\n",
    "# 2. Check for leading/trailing spaces in Country\n",
    "country_check = records[\"Country\"].str.strip()\n",
    "diff_spaces = (records[\"Country\"] != country_check).sum()\n",
    "print(\"Rows with trailing/leading spaces in Country:\", diff_spaces)\n",
    "\n",
    "# 3. Check for Unknown City entries\n",
    "unknown_count = (records[\"shipping_city\"] == \"Unknown City\").sum()\n",
    "print(\"Rows with 'Unknown City':\", unknown_count)\n",
    "\n",
    "# 4. Check logic: Ship Date < Order Date\n",
    "invalid_dates = (records[\"Ship Date\"] < records[\"Order Date\"]).sum()\n",
    "print(\"Rows where Ship Date < Order Date:\", invalid_dates)\n",
    "\n",
    "# 5. Check for duplicates\n",
    "duplicate_rows = records.duplicated().sum()\n",
    "print(\"Duplicate rows:\", duplicate_rows)\n",
    "\n",
    "# 6. Check inconsistency in formating.\n",
    "\n",
    "# Check unique Item Types (look for duplicates with different cases)\n",
    "print(\"Unique Item Types:\", records[\"Item Type\"].unique())\n",
    "\n",
    "# Lowercased version to spot duplicates\n",
    "print(\"Unique Item Types (lowercased):\", records[\"Item Type\"].str.lower().unique())\n",
    "\n",
    "# Check for country name inconsistencies\n",
    "print(\"Unique Countries (sample 20):\", records[\"Country\"].unique()[:20])\n",
    "\n",
    "# 7. Check for outliners in price.\n",
    "\n",
    "# Check for zero or negative Units Sold\n",
    "invalid_units = records[records[\"Units Sold\"] <= 0]\n",
    "print(\"Invalid Units Sold count:\", len(invalid_units))\n",
    "\n",
    "# Very large values (outliers) – for example > 10,000\n",
    "outliers = records[records[\"Units Sold\"] > 10000]\n",
    "print(\"Outlier Units Sold count:\", len(outliers))\n",
    "\n",
    "# Check if totals match formulas\n",
    "invalid_revenue = records[\n",
    "    (records[\"Units Sold\"] * records[\"Unit Price\"]).round(2) != records[\"Total Revenue\"].round(2)\n",
    "]\n",
    "invalid_cost = records[\n",
    "    (records[\"Units Sold\"] * records[\"Unit Cost\"]).round(2) != records[\"Total Cost\"].round(2)\n",
    "]\n",
    "invalid_profit = records[\n",
    "    (records[\"Total Revenue\"] - records[\"Total Cost\"]).round(2) != records[\"Total Profit\"].round(2)\n",
    "]\n",
    "\n",
    "print(\"Invalid Revenue rows:\", len(invalid_revenue))\n",
    "print(\"Invalid Cost rows:\", len(invalid_cost))\n",
    "print(\"Invalid Profit rows:\", len(invalid_profit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bcf1d",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We validated the dataset across multiple dimensions to identify possible dirty data cases:\n",
    "\n",
    "1. **Date columns**  \n",
    "   - Both `Order Date` and `Ship Date` are already stored as `datetime64[ns]`.  \n",
    "   - No rows found where `Ship Date < Order Date`.  \n",
    "\n",
    "2. **Text field formatting**  \n",
    "   - `Country` column contained 22 rows with trailing/leading whitespace, which can cause duplicates like `\"Canada\"` vs `\"Canada \"`.  \n",
    "   - `Item Type` was consistent — unique values matched after lowercasing, so no case-duplication issues were found.  \n",
    "\n",
    "3. **Missing/unmapped values**  \n",
    "   - 38 rows had `\"Unknown City\"` in the derived `shipping_city` column. These represent missing mappings when converting from country to capital city.  \n",
    "\n",
    "4. **Numeric validation**  \n",
    "   - `Units Sold`: No invalid values (≤ 0) and no extreme outliers (> 10,000).  \n",
    "   - Revenue, Cost, and Profit calculations matched expected formulas in all rows.  \n",
    "\n",
    "5. **Duplicates**  \n",
    "   - ✅ No duplicate rows detected.  \n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Conclusion\n",
    "The dataset is relatively clean and well-structured.  \n",
    "The main grime cases are:  \n",
    "- **22 rows** with extra spaces in `Country`,  \n",
    "- **38 rows** with `\"Unknown City\"`, and  \n",
    "- the need to ensure **dates are consistently treated as `datetime64[ns]`**.  \n",
    "\n",
    "Other aspects (numeric consistency, duplicates, case sensitivity) did not show problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b1e6b",
   "metadata": {},
   "source": [
    "#### 7. Cleaning Rules\n",
    "Lets apply the cleaning rules to the grime cases that was found above.\n",
    "* Strip whitespace → Removed leading/trailing spaces in `Country` and other text columns (22 rows affected).  \n",
    "* City mapping → Replaced `\"Unknown City\"` entries in `shipping_city` with a safe fallback (`\"<Country> City\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ef7a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country whitespace → before: 22, after: 0\n",
      "Unknown City → before: 38, after: 0\n",
      "Row*Column after cleaning: (500, 15)\n"
     ]
    }
   ],
   "source": [
    "def clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    \n",
    "    # 1) Strip whitespace in text/object columns\n",
    "    for c in out.select_dtypes(include=\"object\").columns:\n",
    "        out[c] = out[c].str.strip()\n",
    "    \n",
    "    # 2) Replace \"Unknown City\" with \"<Country> City\" (only if column exists)\n",
    "    if \"shipping_city\" in out.columns:\n",
    "        mask = out[\"shipping_city\"].eq(\"Unknown City\")\n",
    "        out.loc[mask, \"shipping_city\"] = out.loc[mask, \"Country\"] + \" City\"\n",
    "    \n",
    "    return out\n",
    "\n",
    "# ---- Run before/after comparison\n",
    "before_spaces = (records[\"Country\"] != records[\"Country\"].str.strip()).sum()\n",
    "before_unknown = (records[\"shipping_city\"] == \"Unknown City\").sum() if \"shipping_city\" in records.columns else \"N/A\"\n",
    "\n",
    "cleaned = clean(records)\n",
    "\n",
    "after_spaces = (cleaned[\"Country\"] != cleaned[\"Country\"].str.strip()).sum()\n",
    "after_unknown = (cleaned[\"shipping_city\"] == \"Unknown City\").sum() if \"shipping_city\" in cleaned.columns else \"N/A\"\n",
    "\n",
    "print(f\"Country whitespace → before: {before_spaces}, after: {after_spaces}\")\n",
    "print(f\"Unknown City → before: {before_unknown}, after: {after_unknown}\")\n",
    "print(\"Row*Column after cleaning:\", cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d46fd5",
   "metadata": {},
   "source": [
    "#### 8. Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48c5d0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before date dtype change:\n",
      "Order Date    object\n",
      "Ship Date     object\n",
      "dtype: object\n",
      "Order Date    500\n",
      "Ship Date     500\n",
      "dtype: int64\n",
      "0    10/18/2014\n",
      "1     11/7/2011\n",
      "2    10/31/2016\n",
      "3     4/10/2010\n",
      "4     8/16/2011\n",
      "Name: Order Date, dtype: object\n",
      "\n",
      "After date dtype change:\n",
      "Order Date    datetime64[ns]\n",
      "Ship Date     datetime64[ns]\n",
      "dtype: object\n",
      "Order Date    500\n",
      "Ship Date     500\n",
      "dtype: int64\n",
      "0   2014-10-18\n",
      "1   2011-11-07\n",
      "2   2016-10-31\n",
      "3   2010-04-10\n",
      "4   2011-08-16\n",
      "Name: Order Date, dtype: datetime64[ns]\n",
      "\n",
      "Coupon summary (first 5):\n",
      "  coupon_code  discount_pct  unit_price_after_discount  net_revenue  \\\n",
      "0      SAVE05          0.05                     415.34   3507961.64   \n",
      "1      SAVE10          0.10                     138.65    418445.70   \n",
      "2      SAVE05          0.05                     242.52    367902.84   \n",
      "3      SAVE20          0.20                     164.56    546668.32   \n",
      "4        NONE          0.00                       9.33     91853.85   \n",
      "\n",
      "   net_profit  \n",
      "0  1283876.46  \n",
      "1   144018.96  \n",
      "2   126062.70  \n",
      "3   157628.90  \n",
      "4    23726.45  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transform(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # --- Dates: BEFORE ---\n",
    "    print(\"\\nBefore date dtype change:\")\n",
    "    print(out[['Order Date','Ship Date']].dtypes)\n",
    "    print(out[['Order Date','Ship Date']].count())\n",
    "    print(out['Order Date'].head(5))\n",
    "\n",
    "    # Convert to datetime (coerce bad values -> NaT)\n",
    "    out['Order Date'] = pd.to_datetime(out['Order Date'], errors='coerce')\n",
    "    out['Ship Date']  = pd.to_datetime(out['Ship Date'],  errors='coerce')\n",
    "\n",
    "    # --- Dates: AFTER ---\n",
    "    print(\"\\nAfter date dtype change:\")\n",
    "    print(out[['Order Date','Ship Date']].dtypes)\n",
    "    print(out[['Order Date','Ship Date']].count())\n",
    "    print(out['Order Date'].head(5))\n",
    "\n",
    "    # --- Coupon transform (simple & deterministic) ---\n",
    "    if 'coupon_code' not in out.columns:\n",
    "        codes = ['NONE','SAVE05','SAVE10','SAVE15','SAVE20']\n",
    "        out['coupon_code'] = out['Order ID'].astype(int).mod(len(codes)).map(dict(enumerate(codes)))\n",
    "\n",
    "    # Parse % from coupon_code -> discount in [0,1]\n",
    "    out['discount_pct'] = (\n",
    "        out['coupon_code'].astype(str).str.upper().str.extract(r'(\\d{1,2})')[0]\n",
    "        .astype(float).fillna(0).clip(0,100).div(100)\n",
    "    )\n",
    "\n",
    "    # Derived fields (don’t overwrite originals)\n",
    "    out['unit_price_after_discount'] = (out['Unit Price'] * (1 - out['discount_pct'])).round(2)\n",
    "    out['discount_amount'] = (out['Unit Price'] - out['unit_price_after_discount']).round(2)\n",
    "    out['net_revenue'] = (out['unit_price_after_discount'] * out['Units Sold']).round(2)\n",
    "    out['net_profit']  = (out['net_revenue'] - out['Total Cost']).round(2)\n",
    "\n",
    "    # Tiny summary\n",
    "    print(\"\\nCoupon summary (first 5):\")\n",
    "    print(out[['coupon_code','discount_pct','unit_price_after_discount','net_revenue','net_profit']].head(5))\n",
    "\n",
    "    return out\n",
    "\n",
    "# Run\n",
    "df_transformed = transform(cleaned if 'cleaned' in locals() else records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691b57c",
   "metadata": {},
   "source": [
    "#### 9. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbd55ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id Order Date  Ship Date  days_to_ship  profit_margin_pct\n",
      "0            1 2014-10-18 2014-10-31            13              39.77\n",
      "1            2 2011-11-07 2011-12-08            31              40.98\n",
      "2            3 2016-10-31 2016-12-09            39              37.55\n",
      "3            4 2010-04-10 2010-05-12            32              43.07\n",
      "4            5 2011-08-16 2011-08-31            15              25.83\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # 1) Add customer_id (unique row index starting at 1)\n",
    "    out[\"customer_id\"] = range(1, len(out) + 1)\n",
    "\n",
    "    # 2) Days to ship (requires datetime columns)\n",
    "    if pd.api.types.is_datetime64_any_dtype(out[\"Order Date\"]) and pd.api.types.is_datetime64_any_dtype(out[\"Ship Date\"]):\n",
    "        out[\"days_to_ship\"] = (out[\"Ship Date\"] - out[\"Order Date\"]).dt.days\n",
    "\n",
    "    # 3) Profit margin percentage\n",
    "    out[\"profit_margin_pct\"] = ((out[\"Total Profit\"] / out[\"Total Revenue\"]) * 100).round(2)\n",
    "\n",
    "    # Preview\n",
    "    print(out[[\"customer_id\", \"Order Date\", \"Ship Date\", \"days_to_ship\", \"profit_margin_pct\"]].head(5))\n",
    "    return out\n",
    "\n",
    "# Run\n",
    "df_features = feature_engineering(df_transformed if \"df_transformed\" in locals() else records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8fa34a",
   "metadata": {},
   "source": [
    "#### 10. \tMini-Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa466488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 cities by revenue:\n",
      "shipping_city\n",
      "Unknown City    36417096.86\n",
      "Port Moresby    15629197.78\n",
      "San José        15578320.59\n",
      "Name: Total Revenue, dtype: float64\n",
      "Unknown City: 36417096.86\n",
      "Port Moresby: 15629197.78\n",
      "San José: 15578320.59\n"
     ]
    }
   ],
   "source": [
    "# --- Step 10: Mini-Aggregation ---\n",
    "\n",
    "# Aggregate total revenue by shipping city\n",
    "revenue_by_city = (\n",
    "    records.groupby(\"shipping_city\")[\"Total Revenue\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Show top 3 cities\n",
    "print(\"Top 3 cities by revenue:\")\n",
    "print(revenue_by_city.head(3))\n",
    "\n",
    "# Optionally convert to dictionary (for JSON-friendly format)\n",
    "revenue_dict = revenue_by_city.to_dict()\n",
    "\n",
    "# Preview sample from dictionary\n",
    "for k, v in list(revenue_dict.items())[:3]:\n",
    "    print(f\"{k}: {v:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71197438",
   "metadata": {},
   "source": [
    "#### 11. Serialization Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6af9e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to ../data/cleaned_records.json\n",
      "Reloaded shape: (500, 15)\n",
      "First 2 rows from reloaded JSON:\n",
      "                         Region Country   Item Type Sales Channel  \\\n",
      "0  Middle East and North Africa   Libya   Cosmetics       Offline   \n",
      "1                 North America  Canada  Vegetables        Online   \n",
      "\n",
      "  Order Priority  Order Date   Order ID   Ship Date  Units Sold  Unit Price  \\\n",
      "0              M  10/18/2014  686800706  10/31/2014        8446      437.20   \n",
      "1              M   11/7/2011  185941302   12/8/2011        3018      154.06   \n",
      "\n",
      "   Unit Cost  Total Revenue  Total Cost  Total Profit shipping_city  \n",
      "0     263.33     3692591.20  2224085.18    1468506.02       Tripoli  \n",
      "1      90.93      464953.08   274426.74     190526.34        Ottawa  \n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset to JSON\n",
    "output_path = \"../data/cleaned_records.json\"\n",
    "cleaned.to_json(output_path, orient=\"records\", lines=True)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_path}\")\n",
    "\n",
    "# Quick validation: read back the JSON\n",
    "reloaded = pd.read_json(output_path, orient=\"records\", lines=True)\n",
    "\n",
    "print(\"Reloaded shape:\", reloaded.shape)\n",
    "print(\"First 2 rows from reloaded JSON:\")\n",
    "print(reloaded.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69180352",
   "metadata": {},
   "source": [
    "#### Step 12 — Soft Interview Reflection\n",
    "\n",
    "Using functions throughout this lab was essential for writing clean and reusable code.  \n",
    "Instead of repeating the same logic (e.g., converting dates, cleaning whitespace, or mapping cities), functions allowed me to encapsulate each task with clear inputs and outputs. This reduced errors, made debugging easier, and kept the notebook more organized. Functions also made testing more straightforward — I could run them on a sample dataset before applying to the full records. Most importantly, functions support collaboration: teammates can read, reuse, or extend my code without needing to understand every line in detail. Overall, functions increased clarity, reusability, and efficiency in the data-preprocessing workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb7d2b",
   "metadata": {},
   "source": [
    "#### Data Dictionary (Summary)\n",
    "\n",
    "- **Primary CSV fields**: Region, Country, Item Type, Sales Channel, Order Priority, Order Date, Order ID, Ship Date, Units Sold, Unit Price, Unit Cost, Total Revenue, Total Cost, Total Profit.  \n",
    "  *Types:* object, int64, float64, datetime64[ns].  \n",
    "\n",
    "- **Derived fields**:  \n",
    "  * `shipping_city` → capital mapped from Country (with \"Unknown City\" handled).  \n",
    "  * `customer_id` → synthetic unique ID (1…n).  \n",
    "  * `days_since_purchase` → calculated days between Order Date and reference date.  \n",
    "  * `coupon_code` + `discount_pct` → synthetically generated discounts.  \n",
    "  * `unit_price_after_discount`, `discount_amount`, `net_revenue`, `net_profit` → computed from coupon rules.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03358e",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "| Field                     | Type          | Description                                                     | Source     |\n",
    "|---------------------------|---------------|-----------------------------------------------------------------|------------|\n",
    "| Region                    | object        | Geographic region of sales                                      | Primary CSV|\n",
    "| Country                   | object        | Country of transaction (whitespace cleaned)                     | Primary CSV|\n",
    "| Item Type                 | object        | Product category (e.g., Cosmetics, Vegetables, Baby Food)       | Primary CSV|\n",
    "| Sales Channel             | object        | Sales channel (Online/Offline)                                  | Primary CSV|\n",
    "| Order Priority            | object        | Priority code (H = High, M = Medium, L = Low, C = Critical)     | Primary CSV|\n",
    "| Order Date                | datetime64[ns]| Date when the order was placed                                  | Primary CSV|\n",
    "| Order ID                  | int64         | Unique identifier for the order                                 | Primary CSV|\n",
    "| Ship Date                 | datetime64[ns]| Date when the order was shipped                                 | Primary CSV|\n",
    "| Units Sold                | int64         | Quantity sold                                                   | Primary CSV|\n",
    "| Unit Price                | float64       | Price per unit                                                  | Primary CSV|\n",
    "| Unit Cost                 | float64       | Cost per unit                                                   | Primary CSV|\n",
    "| Total Revenue             | float64       | Computed: Units Sold × Unit Price                               | Primary CSV|\n",
    "| Total Cost                | float64       | Computed: Units Sold × Unit Cost                                | Primary CSV|\n",
    "| Total Profit              | float64       | Computed: Total Revenue − Total Cost                            | Primary CSV|\n",
    "| shipping_city             | object        | Capital city mapped from Country (Unknown City filled/fixed)    | Derived    |\n",
    "| customer_id               | int64         | Synthetic unique customer ID (1…n)                              | Synthetic  |\n",
    "| days_since_purchase       | int64         | Days between Order Date and reference date (2025-09-30)         | Derived    |\n",
    "| coupon_code               | object        | Synthetic coupon generated from Order ID                        | Synthetic  |\n",
    "| discount_pct              | float64       | Numeric discount parsed from coupon_code (0–0.20)               | Derived    |\n",
    "| unit_price_after_discount | float64       | Unit price after applying discount                              | Derived    |\n",
    "| discount_amount           | float64       | Amount reduced per unit due to coupon                           | Derived    |\n",
    "| net_revenue               | float64       | Revenue after discounts (unit_price_after_discount × Units Sold)| Derived    |\n",
    "| net_profit                | float64       | Profit after discounts (net_revenue − Total Cost)               | Derived    |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
